{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input/covid19countryinfo.csv\n",
      "./input/SIR_data.csv\n",
      "./input/states-daily.csv\n",
      "./input/covid19-deepscore.csv\n",
      "./input/population_data.csv\n",
      "./input/full-list-total-tests-for-covid-19.csv\n",
      "./input/country_codes.csv\n",
      "./input/enriched_covid_19_week_2.csv\n",
      "./input/covid19-global-forecasting-week-3/test.csv\n",
      "./input/covid19-global-forecasting-week-3/submission.csv\n",
      "./input/covid19-global-forecasting-week-3/train.csv\n",
      "./input/korea/SeoulFloating.csv\n",
      "./input/korea/TimeAge.csv\n",
      "./input/korea/SearchTrend.csv\n",
      "./input/korea/TimeProvince.csv\n",
      "./input/korea/Weather.csv\n",
      "./input/korea/PatientRoute.csv\n",
      "./input/korea/PatientInfo.csv\n",
      "./input/korea/Region.csv\n",
      "./input/korea/TimeGender.csv\n",
      "./input/korea/Case.csv\n",
      "./input/korea/Time.csv\n",
      "./input/covid19-global-forecasting-week-2/test.csv\n",
      "./input/covid19-global-forecasting-week-2/submission.csv\n",
      "./input/covid19-global-forecasting-week-2/train.csv\n",
      "./input/covidAPI/ESP.json\n",
      "./input/covidAPI/ICL.json\n",
      "./input/covidAPI/CHN.json\n",
      "./input/covidAPI/FRA.json\n",
      "./input/covidAPI/THA.json\n",
      "./input/covidAPI/DNK.json\n",
      "./input/covidAPI/DEU.json\n",
      "./input/covidAPI/KOR.json\n",
      "./input/covidAPI/TWN.json\n",
      "./input/covidAPI/ISL.json\n",
      "./input/covidAPI/ITA.json\n",
      "./input/.ipynb_checkpoints/SIR_data-checkpoint.csv\n",
      "./input/.ipynb_checkpoints/covid19-deepscore-checkpoint.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk('./input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_in_sequence = 21\n",
    "output_days = 7\n",
    "\n",
    "sequence_length = days_in_sequence - 1\n",
    "training_percentage = 0.9\n",
    "temp_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 20, 64)       17408       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           12416       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           12416       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           528         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           528         lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            119         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7)            119         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "infectious (LeakyReLU)          (None, 7)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "removed (LeakyReLU)             (None, 7)            0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 43,534\n",
      "Trainable params: 43,534\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#temporal input branch\n",
    "temporal_input_layer = Input(shape=(sequence_length,temp_dim))\n",
    "main_rnn_layer = layers.LSTM(64, return_sequences=True, recurrent_dropout=0.2)(temporal_input_layer)\n",
    "\n",
    "#demographic input branch\n",
    "# demographic_input_layer = Input(shape=(dem_dim,))\n",
    "# demographic_dense = layers.Dense(16)(demographic_input_layer)\n",
    "# demographic_dropout = layers.Dropout(0.2)(demographic_dense)\n",
    "\n",
    "#cases output branch\n",
    "rnn_c = layers.LSTM(32)(main_rnn_layer)\n",
    "# merge_c = layers.Concatenate(axis=-1)([rnn_c,demographic_dropout])\n",
    "dense_c = layers.Dense(16)(rnn_c)\n",
    "dropout_c = layers.Dropout(0.2)(dense_c)\n",
    "output_c = layers.Dense(7)(dropout_c) #activation=layers.LeakyReLU(alpha=0.1)\n",
    "cases = layers.LeakyReLU(alpha=0.1,name=\"infectious\")(output_c)\n",
    "\n",
    "#fatality output branch\n",
    "rnn_f = layers.LSTM(32)(main_rnn_layer)\n",
    "# merge_f = layers.Concatenate(axis=-1)([rnn_f,demographic_dropout])\n",
    "dense_f = layers.Dense(16)(rnn_f)\n",
    "dropout_f = layers.Dropout(0.2)(dense_f)\n",
    "output_f = layers.Dense(7)(dropout_f)\n",
    "fatalities = layers.LeakyReLU(alpha=0.1, name=\"removed\")(output_f)\n",
    "\n",
    "\n",
    "model = Model([temporal_input_layer], [cases,fatalities])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', verbose=1, factor=0.6), #patience=4  #EarlyStopping(monitor='val_loss', patience=20)\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "model.compile(loss=[tf.keras.losses.mean_squared_logarithmic_error,tf.keras.losses.mean_squared_logarithmic_error], optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will retrieve the number of cases and fatalities for the past 14\n",
    "def build_inputs_for_date_code(code, date, gdf):\n",
    "    start_date = date - timedelta(days=days_in_sequence-1) # input start date\n",
    "    end_date = date - timedelta(days=1) # input end date\n",
    "    \n",
    "    str_start_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "    str_end_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "    tdf = gdf[(gdf[\"Code\"] == code) & (gdf[\"Date\"] >= str_start_date) & (gdf[\"Date\"] <= str_end_date)]\n",
    "\n",
    "    \n",
    "    #preparing the temporal inputs\n",
    "    temporal_input_data = np.transpose(np.reshape(np.asarray([tdf[\"infectious_noise_rate\"],\n",
    "                                                 tdf[\"removed_noise_rate\"],\n",
    "                                                 tdf[\"susceptible_noise_rate\"]]),\n",
    "                                     (3,sequence_length)), (1,0) ).astype(np.float32)\n",
    "    \n",
    "    return [np.array([temporal_input_data])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a dataframe in input, will do the predictions and return the dataframe with extra rows\n",
    "#containing the predictions\n",
    "def predict_for_code(code, pdf, gdf):\n",
    "    tdf = pdf[pdf[\"Code\"]==code]\n",
    "    # begin_prediction = \"2020-03-26\"\n",
    "    begin_prediction = tdf.iloc[0][\"Date\"]\n",
    "    start_date = datetime.strptime(begin_prediction,\"%Y-%m-%d\") + timedelta(days_in_sequence) #start of the prediction date\n",
    "    print(\"prediction start date: {}\".format(datetime.strftime(start_date, \"%Y-%m-%d\")))\n",
    "    # end_prediction = \"2020-04-15\"\n",
    "    end_prediction = tdf.iloc[-1][\"Date\"]\n",
    "    end_date = datetime.strptime(end_prediction,\"%Y-%m-%d\")\n",
    "    \n",
    "    date_list = [start_date + timedelta(days=x) for x in range(0, (end_date-start_date).days+1, output_days+1)]\n",
    "    for date in date_list:\n",
    "        date_until = date + timedelta(days=output_days-1)\n",
    "        input_data = build_inputs_for_date_code(code, date, gdf)\n",
    "        result = model.predict(input_data)\n",
    "\n",
    "        # add predicted results\n",
    "        # pdf.loc[(pdf[\"Code\"] == code) & (pdf[\"Date\"] == date.strftime(\"%Y-%m-%d\")), [\"infectious_rate\", \"removed_rate\"]] = [result[0][0][0], result[1][0][0]]\n",
    "        try:\n",
    "            pdf.loc[(pdf[\"Code\"] == code) & (pdf[\"Date\"] >= date.strftime(\"%Y-%m-%d\")) & (pdf[\"Date\"] <= date_until.strftime(\"%Y-%m-%d\")), [\"infectious_noise_rate\"]] = result[0][0].tolist()\n",
    "            pdf.loc[(pdf[\"Code\"] == code) & (pdf[\"Date\"] >= date.strftime(\"%Y-%m-%d\")) & (pdf[\"Date\"] <= date_until.strftime(\"%Y-%m-%d\")), [\"removed_noise_rate\"]] = result[1][0].tolist()\n",
    "        except:\n",
    "            print(date)\n",
    "            print(result)\n",
    "        \n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will retrieve the number of cases and fatalities for the past 14\n",
    "def build_inputs_for_date(code, date, gdf):\n",
    "    start_date = date - timedelta(days=days_in_sequence-1) # input start date\n",
    "    end_date = date - timedelta(days=1) # input end date\n",
    "    \n",
    "    str_start_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "    str_end_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "    tdf = gdf[(gdf[\"Code\"] == code) & (gdf[\"Date\"] >= str_start_date) & (gdf[\"Date\"] <= str_end_date)]\n",
    "\n",
    "    \n",
    "    #preparing the temporal inputs\n",
    "    temporal_input_data = np.transpose(np.reshape(np.asarray([tdf[\"infectious_rate\"],\n",
    "                                                 tdf[\"removed_rate\"],\n",
    "                                                 tdf[\"susceptible_rate\"]]),\n",
    "                                     (3,sequence_length)), (1,0) ).astype(np.float32)\n",
    "    \n",
    "    return [np.array([temporal_input_data])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a dataframe in input, will do the predictions and return the dataframe with extra rows\n",
    "#containing the predictions\n",
    "def predict_for_region(code, pdf, gdf):\n",
    "    tdf = pdf[pdf[\"Code\"]==code]\n",
    "    # begin_prediction = \"2020-03-26\"\n",
    "    begin_prediction = tdf.iloc[0][\"Date\"]\n",
    "    start_date = datetime.strptime(begin_prediction,\"%Y-%m-%d\") + timedelta(days_in_sequence) #start of the prediction date\n",
    "    print(\"prediction start date: {}\".format(datetime.strftime(start_date, \"%Y-%m-%d\")))\n",
    "    # end_prediction = \"2020-04-15\"\n",
    "    end_prediction = tdf.iloc[-1][\"Date\"]\n",
    "    end_date = datetime.strptime(end_prediction,\"%Y-%m-%d\")\n",
    "    \n",
    "    date_list = [start_date + timedelta(days=x) for x in range(0, (end_date-start_date).days+1, output_days+1)]\n",
    "    for date in date_list:\n",
    "        date_until = date + timedelta(days=output_days-1)\n",
    "        input_data = build_inputs_for_date(code, date, gdf)\n",
    "        result = model.predict(input_data)\n",
    "\n",
    "        # add predicted results\n",
    "        # pdf.loc[(pdf[\"Code\"] == code) & (pdf[\"Date\"] == date.strftime(\"%Y-%m-%d\")), [\"infectious_rate\", \"removed_rate\"]] = [result[0][0][0], result[1][0][0]]\n",
    "        try:\n",
    "            pdf.loc[(pdf[\"Code\"] == code) & (pdf[\"Date\"] >= date.strftime(\"%Y-%m-%d\")) & (pdf[\"Date\"] <= date_until.strftime(\"%Y-%m-%d\")), [\"infectious_rate\"]] = result[0][0].tolist()\n",
    "            pdf.loc[(pdf[\"Code\"] == code) & (pdf[\"Date\"] >= date.strftime(\"%Y-%m-%d\")) & (pdf[\"Date\"] <= date_until.strftime(\"%Y-%m-%d\")), [\"removed_rate\"]] = result[1][0].tolist()\n",
    "        except:\n",
    "            print(date)\n",
    "            print(result)\n",
    "        \n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-1.4338503e-05,  9.8903198e-05,  1.6754027e-04,  2.4142629e-04,\n",
      "         3.5245204e-04,  3.0315993e-04,  5.0156470e-04]], dtype=float32), array([[0.00252245, 0.00263636, 0.00282572, 0.0028567 , 0.00297518,\n",
      "        0.00313732, 0.00335079]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-4.8375132e-05, -1.9078050e-05, -2.4863100e-05, -1.6765669e-05,\n",
      "        -4.5862980e-06, -2.1150057e-05, -1.0633422e-05]], dtype=float32), array([[0.01142811, 0.01156685, 0.01175958, 0.01180415, 0.0119391 ,\n",
      "        0.01206946, 0.0122559 ]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-6.6596083e-05, -3.4566132e-05, -4.7166694e-05, -3.8716851e-05,\n",
      "        -2.5958614e-05, -4.8757811e-05, -4.3305663e-05]], dtype=float32), array([[0.01631457, 0.016467  , 0.01666197, 0.01671394, 0.01685796,\n",
      "        0.01697147, 0.01714424]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-7.9014899e-05, -4.5114150e-05, -6.2378822e-05, -5.3699921e-05,\n",
      "        -4.0546245e-05, -6.7598608e-05, -6.5628723e-05]], dtype=float32), array([[0.01969551, 0.01985744, 0.02005414, 0.02011119, 0.0202615 ,\n",
      "        0.0203636 , 0.0205274 ]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-1.4841324e-05,  9.4618648e-05,  1.6139587e-04,  2.3538992e-04,\n",
      "         3.4657866e-04,  2.9556826e-04,  4.9260771e-04]], dtype=float32), array([[0.00265212, 0.00276639, 0.00295579, 0.00298696, 0.0031057 ,\n",
      "        0.00326735, 0.00348041]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-0.00053781, -0.00042624, -0.00063964, -0.00063568, -0.00060529,\n",
      "        -0.00079312, -0.00095614]], dtype=float32), array([[0.20736676, 0.20809123, 0.20857859, 0.20887959, 0.20940483,\n",
      "        0.20913975, 0.2093988 ]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-7.2201852e-05, -3.9328308e-05, -5.4032404e-05, -4.5477926e-05,\n",
      "        -3.2541437e-05, -5.7260135e-05, -5.3376705e-05]], dtype=float32), array([[0.01783569, 0.01799239, 0.01818812, 0.01824238, 0.01838922,\n",
      "        0.01849758, 0.01866626]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-0.0001771 , -0.00012817, -0.00018288, -0.00017276, -0.00015644,\n",
      "        -0.00021717, -0.0002437 ]], dtype=float32), array([[0.04802933, 0.04827185, 0.04848813, 0.04858697, 0.0487904 ,\n",
      "        0.04880433, 0.0489084 ]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-5.0336264e-05, -2.0745443e-05, -2.7262886e-05, -1.9126619e-05,\n",
      "        -6.8847089e-06, -2.4119392e-05, -1.4145393e-05]], dtype=float32), array([[0.01195003, 0.01209023, 0.01228319, 0.01232855, 0.01246447,\n",
      "        0.01259301, 0.01277795]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-8.9106710e-05, -5.3680735e-05, -7.4747113e-05, -6.5889260e-05,\n",
      "        -5.2413623e-05, -8.2923703e-05, -8.3803061e-05]], dtype=float32), array([[0.02247405, 0.02264381, 0.02284202, 0.02290324, 0.02305872,\n",
      "        0.02315158, 0.0233083 ]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-0.00026311, -0.00020055, -0.0002892 , -0.00027845, -0.00025926,\n",
      "        -0.0003497 , -0.00040297]], dtype=float32), array([[0.07584089, 0.0761641 , 0.0764084 , 0.07654667, 0.07680316,\n",
      "        0.07674305, 0.07681498]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-1.07364634e-04, -6.91674213e-05, -9.71391346e-05,\n",
      "        -8.79740328e-05, -7.39137176e-05, -1.10684014e-04,\n",
      "        -1.16762334e-04]], dtype=float32), array([[0.02757496, 0.02775914, 0.02796036, 0.02802919, 0.02819418,\n",
      "        0.02827043, 0.02841485]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-9.4745310e-06,  1.4033541e-04,  2.2696750e-04,  2.9978622e-04,\n",
      "         4.0927948e-04,  3.7660170e-04,  5.8819167e-04]], dtype=float32), array([[0.00127224, 0.00138268, 0.00157163, 0.00160069, 0.00171687,\n",
      "        0.00188358, 0.00210107]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-0.00023871, -0.00018006, -0.00025896, -0.00024831, -0.00022995,\n",
      "        -0.00031195, -0.00035743]], dtype=float32), array([[0.06761198, 0.06791116, 0.06814627, 0.06827305, 0.06851374,\n",
      "        0.06847429, 0.06855303]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-2.43274499e-05,  1.38394535e-05,  4.54620458e-05,\n",
      "         1.21492893e-04,  2.35674903e-04,  1.52257271e-04,\n",
      "         3.23477667e-04]], dtype=float32), array([[0.00510722, 0.00522832, 0.00541856, 0.00545349, 0.00557675,\n",
      "        0.00572952, 0.00593486]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-4.9302496e-05, -1.9866648e-05, -2.5997917e-05, -1.7882092e-05,\n",
      "        -5.6732911e-06, -2.2554164e-05, -1.2293877e-05]], dtype=float32), array([[0.01167476, 0.01181418, 0.01200702, 0.01205196, 0.01218737,\n",
      "        0.01231688, 0.0125026 ]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-1.3427493e-04, -9.1964284e-05, -1.3018228e-04, -1.2060478e-04,\n",
      "        -1.0567829e-04, -1.5168577e-04, -1.6553831e-04]], dtype=float32), array([[0.0352768 , 0.03548284, 0.03568917, 0.0357694 , 0.03594881,\n",
      "        0.03600078, 0.03612833]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-0.00047169, -0.00037322, -0.0005523 , -0.00054445, -0.00051737,\n",
      "        -0.00068108, -0.00081146]], dtype=float32), array([[0.1645796 , 0.1651701 , 0.16555916, 0.16581163, 0.16624564,\n",
      "        0.16602346, 0.16616204]], dtype=float32)]\n",
      "prediction start date: 2020-02-22\n",
      "2020-07-07 00:00:00\n",
      "[array([[-0.00029535, -0.00022754, -0.00032927, -0.00031849, -0.00029819,\n",
      "        -0.00039982, -0.00046366]], dtype=float32), array([[0.08719939, 0.08755599, 0.08781418, 0.08796807, 0.08824654,\n",
      "        0.08815958, 0.0882258 ]], dtype=float32)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ef99443c9a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Predictions for countries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest_country\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"KOR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ITA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FRA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEU\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ISL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DNK\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"THA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TWN\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code in {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_country\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# prediction data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mcpdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"infectious_rate\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcpdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"removed_rate\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Predictions for SIR\n",
    "SIR_df = pd.read_csv(\"./input/SIR_data.csv\")\n",
    "pdf = SIR_df.copy()\n",
    "pdf[\"infectious_noise_rate\"] = np.nan\n",
    "pdf[\"removed_noise_rate\"] = np.nan\n",
    "gdf = SIR_df.copy()\n",
    "\n",
    "for code in range(81, 100):\n",
    "    pdf = predict_for_code(\"SIR-small-{}\".format(code), pdf, gdf)\n",
    "pdf.to_csv(\"./predictions_SIR.csv\")\n",
    "\n",
    "# Predictions for countries\n",
    "# new_df = pd.read_csv(\"./input/country_data.csv\")\n",
    "# test_country = [\"KOR\", \"ITA\", \"FRA\", \"DEU\", \"ISL\", \"DNK\", \"THA\", \"TWN\"]\n",
    "# cpdf = new_df.copy().query(\"Code in {}\".format(test_country)) # prediction data frame\n",
    "# cpdf[\"infectious_rate\"] = np.nan\n",
    "# cpdf[\"removed_rate\"] = np.nan\n",
    "# cgdf = new_df.copy().query(\"Code in {}\".format(test_country))\n",
    "\n",
    "# for code in test_country:\n",
    "#     cpdf = predict_for_region(code, cpdf, cgdf)\n",
    "# cpdf.to_csv(\"./predictions_countries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Outputs: Observing the curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = gdf.Date.unique()\n",
    "dates = sorted(dates)\n",
    "last_date = dates[-1]\n",
    "print(last_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_comparison_SIR(code, pdf, groundtruth_df):\n",
    "    groundtruth = groundtruth_df[(groundtruth_df[\"Code\"]==code) & (groundtruth_df[\"Date\"]>=\"2020-02-07\")]\n",
    "    prediction = pdf[(pdf[\"Code\"] == code) & (pdf[\"Date\"] >= \"2020-02-07\")]\n",
    "    \n",
    "    plt.plot(groundtruth.infectious_noise_rate.values)\n",
    "    plt.plot(groundtruth.infectious_rate.values)\n",
    "    plt.plot(prediction.infectious_noise_rate.values)\n",
    "    plt.title(\"Comparison between the actual data and our predictions for the number of cases\")\n",
    "    plt.ylabel('Number of cases')\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(range(len(prediction.Date.values)),prediction.Date.values,rotation='vertical')\n",
    "    plt.legend(['Groundtruth with noise', 'Groundtruth', 'Prediction'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(groundtruth.removed_noise_rate.values)\n",
    "    plt.plot(groundtruth.removed_rate.values)\n",
    "    plt.plot(prediction.removed_noise_rate.values)\n",
    "    plt.title(\"Comparison between the actual data and our predictions for the number of fatalities\")\n",
    "    plt.ylabel('Number of fatalities')\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(range(len(prediction.Date.values)),prediction.Date.values,rotation='vertical')\n",
    "    plt.legend(['Groundtruth with noise', 'Groundtruth', 'Prediction'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_comparison_region(code, cpdf, groundtruth_df):\n",
    "    groundtruth = groundtruth_df[(groundtruth_df[\"Code\"]==code) & (groundtruth_df[\"Date\"]>=\"2020-02-07\")]\n",
    "    prediction = cpdf[(cpdf[\"Code\"] == code) & (cpdf[\"Date\"] >= \"2020-02-07\")]\n",
    "    \n",
    "    plt.plot(groundtruth.infectious_rate.values)\n",
    "    plt.plot(prediction.infectious_rate.values)\n",
    "    plt.title(\"Comparison between the actual data and our predictions for the number of cases\")\n",
    "    plt.ylabel('Number of cases')\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(range(len(prediction.Date.values)),prediction.Date.values,rotation='vertical')\n",
    "    plt.legend(['Groundtruth', 'Prediction'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(groundtruth.removed_rate.values)\n",
    "    plt.plot(prediction.removed_rate.values)\n",
    "    plt.title(\"Comparison between the actual data and our predictions for the number of fatalities\")\n",
    "    plt.ylabel('Number of fatalities')\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(range(len(prediction.Date.values)),prediction.Date.values,rotation='vertical')\n",
    "    plt.legend(['Groundtruth', 'Prediction'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in range(81, 100):\n",
    "    print(\"------------------------------SIR-small-{}---------------------------------\".format(code))\n",
    "    display_comparison_SIR(\"SIR-small-{}\".format(code), pdf, gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in test_country:\n",
    "    print(\"------------------------------{}---------------------------------\".format(code))\n",
    "    display_comparison_region(code, cpdf, cgdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
